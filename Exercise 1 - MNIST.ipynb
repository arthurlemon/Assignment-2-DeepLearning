{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "mnist_transforms = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "mnist_train = torchvision.datasets.MNIST(root='./data', train=True, transform=mnist_transforms, download=True)\n",
    "mnist_test = torchvision.datasets.MNIST(root='./data', train=False, transform=mnist_transforms, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "trainloader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Early stopping and weight decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP (nn.Module):\n",
    "    \"\"\"MLP Classifier with 2 hidden layers\"\"\"  \n",
    "    def __init__(self, h0, h1, h2, h3, init_method = 'glorot'):\n",
    "        super(MLP,self).__init__()\n",
    "        \n",
    "        # Creating layers\n",
    "        self.hidden1 = nn.Linear(h0, h1, bias=True)\n",
    "        self.hidden2 = nn.Linear(h1, h2, bias=True)\n",
    "        self.hidden3 = nn.Linear(h2, h3, bias=True)\n",
    "        \n",
    "        # Initializing layers\n",
    "        self.initialize(self.hidden1)\n",
    "        self.initialize(self.hidden2)\n",
    "        self.initialize(self.hidden3)\n",
    "                       \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        out = F.relu(self.hidden1(x))\n",
    "        out = F.relu(self.hidden2(out))\n",
    "        out = self.hidden3(out)\n",
    "        return out\n",
    "    \n",
    "    def predict(self, x):\n",
    "        out = F.softmax(self.forward(x), dim=1)\n",
    "        return out\n",
    "    \n",
    "    def initialize(self, layer):\n",
    "        for k,v in layer.named_parameters():\n",
    "            if k == 'weight':\n",
    "                init.xavier_uniform(v)\n",
    "            if k == 'bias': \n",
    "                init.uniform(v, 0, 0)\n",
    "                \n",
    "def l2norm (layer):\n",
    "    for k,v in layer.named_parameters():\n",
    "        if k =='weight':\n",
    "            return torch.norm(v, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(clf, trainloader, loss_fn, optimizer, epochs=10, verbose = True):\n",
    "    mean_losses = []\n",
    "    train_accuracy = []\n",
    "    l2norm_layer1 =np.array([])\n",
    "    l2norm_layer2 =np.array([])\n",
    "    l2norm_layer3 =np.array([])\n",
    "    \n",
    "    clf.train()\n",
    "    for epoch in range(epochs):\n",
    "        losses = []\n",
    "        # Train\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        t0 = time.clock()\n",
    "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "            optimizer.zero_grad()\n",
    "            inputs, targets = Variable(inputs), Variable(targets)\n",
    "            outputs = clf(inputs)\n",
    "            loss = loss_fn (outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.data[0])\n",
    "\n",
    "            # Training accuracy\n",
    "            _, predicted_train = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted_train.eq(targets.data).sum()\n",
    "            \n",
    "            # Stock the l2 norms\n",
    "            #l2norm_layer1 = np.concatenate((l2norm_layer1, l2norm(clf.hidden1).data.numpy()))  \n",
    "            #l2norm_layer2 = np.concatenate((l2norm_layer2, l2norm(clf.hidden2).data.numpy()))  \n",
    "            #l2norm_layer3 = np.concatenate((l2norm_layer3, l2norm(clf.hidden3).data.numpy()))  \n",
    "                        \n",
    "        t1 = time.clock()    \n",
    "        mean_losses.append(np.mean(losses))\n",
    "        accuracy = 100.0 * correct/total\n",
    "        train_accuracy.append(accuracy)\n",
    "        if verbose == True:\n",
    "            print('Epoch :', epoch)\n",
    "            print('Loss : ',np.mean(losses))\n",
    "            print('Train Acc : ', accuracy, '%')\n",
    "            print(\"Training time took :\", t1-t0, \" secondes\")\n",
    "            print('-----------------')\n",
    "    data = {'mean_losses' : mean_losses,'train_accuracy' : train_accuracy, \n",
    "            'l2norm_layer1': l2norm_layer1,\n",
    "            'l2norm_layer2': l2norm_layer2,\n",
    "            'l2norm_layer3': l2norm_layer3}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With no decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Weights and loss function:\n",
    "h0, h1, h2, h3 = 784, 10, 10, 10\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0\n",
      "Loss :  1.00230149861\n",
      "Train Acc :  67.31 %\n",
      "Training time took : 4.310684745250001  secondes\n",
      "-----------------\n",
      "Epoch : 1\n",
      "Loss :  0.437207603633\n",
      "Train Acc :  87.33833333333334 %\n",
      "Training time took : 4.166363012360307  secondes\n",
      "-----------------\n",
      "Epoch : 2\n",
      "Loss :  0.371538317153\n",
      "Train Acc :  89.34833333333333 %\n",
      "Training time took : 4.189118201031306  secondes\n",
      "-----------------\n",
      "Epoch : 3\n",
      "Loss :  0.333593296765\n",
      "Train Acc :  90.36 %\n",
      "Training time took : 4.236234155649072  secondes\n",
      "-----------------\n",
      "Epoch : 4\n",
      "Loss :  0.308837741097\n",
      "Train Acc :  91.115 %\n",
      "Training time took : 4.390275563204341  secondes\n",
      "-----------------\n",
      "Epoch : 5\n",
      "Loss :  0.291331942195\n",
      "Train Acc :  91.705 %\n",
      "Training time took : 4.4432222552468374  secondes\n",
      "-----------------\n",
      "Epoch : 6\n",
      "Loss :  0.278011647837\n",
      "Train Acc :  92.06333333333333 %\n",
      "Training time took : 4.829264447732385  secondes\n",
      "-----------------\n",
      "Epoch : 7\n",
      "Loss :  0.267472220279\n",
      "Train Acc :  92.395 %\n",
      "Training time took : 4.68584751983235  secondes\n",
      "-----------------\n",
      "Epoch : 8\n",
      "Loss :  0.257660709457\n",
      "Train Acc :  92.595 %\n",
      "Training time took : 4.543472513469169  secondes\n",
      "-----------------\n",
      "Epoch : 9\n",
      "Loss :  0.251188249679\n",
      "Train Acc :  92.875 %\n",
      "Training time took : 4.580940225396262  secondes\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "# Glorot initialization\n",
    "clf = MLP(h0, h1, h2, h3)\n",
    "optimizer = torch.optim.SGD(clf.parameters(),lr=0.02)\n",
    "train_nodecay = training(clf, trainloader, loss_fn, optimizer, epochs, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b20bb4e438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = range(0,len(train_nodecay['l2norm_layer1']))\n",
    "plt.plot(x, train_nodecay['l2norm_layer1'], 'ro', label = \"Layer 1\")\n",
    "plt.plot(x, train_nodecay['l2norm_layer2'], 'bo', label = \"Layer 2\")\n",
    "plt.plot(x, train_nodecay['l2norm_layer3'], 'go', label = \"Layer 3\")\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Weights L2 norm')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b20be586d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = range(0, epochs)\n",
    "plt.plot(x, train_nodecay['mean_losses'], 'ro', label = \"Loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Total loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With L2 regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples:  938\n"
     ]
    }
   ],
   "source": [
    "print('Number of training examples: ',len(trainloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want $ \\lambda = 2.5 $ on the whole training set. \n",
    "Using mini-batch of size 64 give us a new $\\lambda'$ such as\n",
    "\n",
    "$$ \\lambda' = \\frac{64}{n_{train}}\\lambda = \\frac{64}{938}* 2.5 $$\n",
    "\n",
    "$$ \\lambda' = 0.17$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Weights and loss function:\n",
    "h0, h1, h2, h3 = 784, 10, 10, 10\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0\n",
      "Loss :  2.1727104398\n",
      "Train Acc :  21.805 %\n",
      "Training time took : 4.304217688526478  secondes\n",
      "-----------------\n",
      "Epoch : 1\n",
      "Loss :  2.01813890964\n",
      "Train Acc :  24.865 %\n",
      "Training time took : 4.413072625790846  secondes\n",
      "-----------------\n",
      "Epoch : 2\n",
      "Loss :  1.92718420189\n",
      "Train Acc :  31.74 %\n",
      "Training time took : 4.5478048215754825  secondes\n",
      "-----------------\n",
      "Epoch : 3\n",
      "Loss :  1.89636631243\n",
      "Train Acc :  33.20166666666667 %\n",
      "Training time took : 4.3826114051407785  secondes\n",
      "-----------------\n",
      "Epoch : 4\n",
      "Loss :  1.8891696602\n",
      "Train Acc :  33.215 %\n",
      "Training time took : 4.202278926254621  secondes\n",
      "-----------------\n",
      "Epoch : 5\n",
      "Loss :  1.88635867084\n",
      "Train Acc :  33.54666666666667 %\n",
      "Training time took : 4.438319722942651  secondes\n",
      "-----------------\n",
      "Epoch : 6\n",
      "Loss :  1.88847227887\n",
      "Train Acc :  33.693333333333335 %\n",
      "Training time took : 4.881775979480153  secondes\n",
      "-----------------\n",
      "Epoch : 7\n",
      "Loss :  1.88468220836\n",
      "Train Acc :  33.685 %\n",
      "Training time took : 4.3077962661600395  secondes\n",
      "-----------------\n",
      "Epoch : 8\n",
      "Loss :  1.88640955732\n",
      "Train Acc :  33.605 %\n",
      "Training time took : 4.523433792413925  secondes\n",
      "-----------------\n",
      "Epoch : 9\n",
      "Loss :  1.88590885225\n",
      "Train Acc :  33.781666666666666 %\n",
      "Training time took : 5.556720270751612  secondes\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "# Glorot initialization\n",
    "clf = MLP(h0, h1, h2, h3)\n",
    "optimizer = torch.optim.SGD(clf.parameters(),lr=0.02, weight_decay=0.17)\n",
    "train_decay = training(clf, trainloader, loss_fn, optimizer, epochs, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b202a7aba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = range(0,len(train_decay['l2norm_layer1']))\n",
    "plt.plot(x, train_decay['l2norm_layer1'], 'ro', label = \"Layer 1\")\n",
    "plt.plot(x, train_decay['l2norm_layer2'], 'bo', label = \"Layer 2\")\n",
    "plt.plot(x, train_decay['l2norm_layer3'], 'go', label = \"Layer 3\")\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Weights L2 norm')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b20bb449b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = range(0, epochs)\n",
    "plt.plot(x, train_nodecay['mean_losses'], 'ro', label = \"Loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Total loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MLP2 (nn.Module):\n",
    "    \"\"\"MLP Classifier with 2 hidden layers and dropout\"\"\"  \n",
    "    def __init__(self, h0, h1, h2, h3, init_method = 'glorot'):\n",
    "        super(MLP2,self).__init__()\n",
    "        \n",
    "        # Creating layers\n",
    "        self.hidden1 = nn.Linear(h0, h1, bias=True)\n",
    "        self.hidden2 = nn.Linear(h1, h2, bias=True)\n",
    "        self.hidden3 = nn.Linear(h2, h3, bias=True)\n",
    "        \n",
    "        # Initializing layers\n",
    "        self.initialize(self.hidden1)\n",
    "        self.initialize(self.hidden2)\n",
    "        self.initialize(self.hidden3)\n",
    "                       \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        out = F.relu(self.hidden1(x))\n",
    "        out = F.relu(self.hidden2(out))\n",
    "        out = F.dropout(out,p=0.5)\n",
    "        out = self.hidden3(out)\n",
    "        return out\n",
    "    \n",
    "    def predict(self, x):\n",
    "        out = F.softmax(self.forward(x), dim=1)\n",
    "        return out\n",
    "    \n",
    "    def initialize(self, layer):\n",
    "        for k,v in layer.named_parameters():\n",
    "            if k == 'weight':\n",
    "                init.xavier_uniform(v)\n",
    "            if k == 'bias': \n",
    "                init.uniform(v, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Weights and loss function:\n",
    "h0, h1, h2, h3 = 784, 10, 10, 10\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0\n",
      "Loss :  0.974596389353\n",
      "Train Acc :  69.61 %\n",
      "Training time took : 4.552794796469243  secondes\n",
      "-----------------\n",
      "Epoch : 1\n",
      "Loss :  0.423595039099\n",
      "Train Acc :  87.57166666666667 %\n",
      "Training time took : 4.345027103097891  secondes\n",
      "-----------------\n",
      "Epoch : 2\n",
      "Loss :  0.361102384259\n",
      "Train Acc :  89.47833333333334 %\n",
      "Training time took : 4.63344970450089  secondes\n",
      "-----------------\n",
      "Epoch : 3\n",
      "Loss :  0.328097686172\n",
      "Train Acc :  90.50666666666666 %\n",
      "Training time took : 4.445567194496107  secondes\n",
      "-----------------\n",
      "Epoch : 4\n",
      "Loss :  0.303475009504\n",
      "Train Acc :  91.22333333333333 %\n",
      "Training time took : 4.608834410833879  secondes\n",
      "-----------------\n",
      "Epoch : 5\n",
      "Loss :  0.284318348695\n",
      "Train Acc :  91.81 %\n",
      "Training time took : 4.749108331923708  secondes\n",
      "-----------------\n",
      "Epoch : 6\n",
      "Loss :  0.270511150757\n",
      "Train Acc :  92.26333333333334 %\n",
      "Training time took : 4.305393031852873  secondes\n",
      "-----------------\n",
      "Epoch : 7\n",
      "Loss :  0.259751222162\n",
      "Train Acc :  92.525 %\n",
      "Training time took : 4.225560002036218  secondes\n",
      "-----------------\n",
      "Epoch : 8\n",
      "Loss :  0.249811738523\n",
      "Train Acc :  92.835 %\n",
      "Training time took : 4.5177730138202605  secondes\n",
      "-----------------\n",
      "Epoch : 9\n",
      "Loss :  0.243288380124\n",
      "Train Acc :  92.96333333333334 %\n",
      "Training time took : 4.428056097909575  secondes\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "# Glorot initialization\n",
    "clf = MLP2(h0, h1, h2, h3)\n",
    "optimizer = torch.optim.SGD(clf.parameters(),lr=0.02)\n",
    "train_dropout = training(clf, trainloader, loss_fn, optimizer, epochs, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i) Multiply 0.5 to the last hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(clf, testloader):\n",
    "    clf.eval()\n",
    "    # Multiplying weights of last hidden layers by 0.5\n",
    "    clf.hidden2.weight.data = clf.hidden2.weight.data * 5\n",
    "    accuracy = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    t0 = time.clock()\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        inputs, targets = Variable(inputs, volatile=True), Variable(targets,volatile=True)\n",
    "        outputs = clf(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "    t1 = time.clock()    \n",
    "    accuracy = 100.0 * correct/total\n",
    "    data = {'accuracy' : accuracy, 'test time': t1-t0}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 90.1, 'test time': 1.225953288416349}\n"
     ]
    }
   ],
   "source": [
    "print(test(clf,testloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ii) Average of N pre-softmax values before applying softmax and making prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(clf, testloader, N):\n",
    "    clf.eval()  \n",
    "    accuracy = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    t0 = time.clock()\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        inputs, targets = Variable(inputs, volatile=True), Variable(targets,volatile=True)\n",
    "        \n",
    "        outputs = clf(inputs)\n",
    "        \n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "    t1 = time.clock()    \n",
    "    accuracy = 100.0 * correct/total\n",
    "    data = {'accuracy' : accuracy, 'test time': t1-t0}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(iii) Average of N predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i) With Batch-normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \"\"\"Convnet Classifier\"\"\"\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            # Layer 1\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(3, 3), padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 2\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 3\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1),\n",
    "            nn.BatchNorm2d(64),     \n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 4\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "        )\n",
    "        # Logistic Regression\n",
    "        self.clf = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.clf(self.conv(x).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-298-1099d0f1b948>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.02\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain_CNN_batchnorm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-297-72bb60bc74fe>\u001b[0m in \u001b[0;36mtraining\u001b[1;34m(clf, trainloader, loss_fn, optimizer, epochs, verbose)\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Programs\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-294-6997cb2e5f7a>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Programs\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Programs\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Programs\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Programs\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[1;32m--> 277\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Programs\\Anaconda\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, weight, bias, stride, padding, dilation, groups)\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[0m_pair\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbenchmark\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m                 torch.backends.cudnn.deterministic, torch.backends.cudnn.enabled)\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Glorot initialization\n",
    "clf = CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(clf.parameters(),lr=0.02)\n",
    "train_CNN_batchnorm = training(clf, trainloader, loss_fn, optimizer, epochs, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-286-e28f58c5a8b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Programs\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-284-f3008c003fce>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Programs\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Programs\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Programs\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Programs\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\pooling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    141\u001b[0m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[0;32m    142\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m                             self.return_indices)\n\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Programs\\Anaconda\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mmax_pool2d\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    332\u001b[0m     \u001b[0mSee\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;32mclass\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaxPool2d\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m     \"\"\"\n\u001b[1;32m--> 334\u001b[1;33m     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreturn_indices\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def test(clf, testloader):\n",
    "    clf.eval()\n",
    "    # Multiplying weights of last hidden layers by 0.5\n",
    "    clf.hidden2.weight.data = clf.hidden2.weight.data * 5\n",
    "    accuracy = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    t0 = time.clock()\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        inputs, targets = Variable(inputs, volatile=True), Variable(targets,volatile=True)\n",
    "        outputs = clf(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "    t1 = time.clock()    \n",
    "    accuracy = 100.0 * correct/total\n",
    "    data = {'accuracy' : accuracy, 'test time': t1-t0}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ii) Without Batch-normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
